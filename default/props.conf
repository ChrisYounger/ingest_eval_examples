[demutliplexed_datetime_formats]
DATETIME_CONFIG = CURRENT
TRANSFORMS-extract_date = demultiplex_datetime

[compound_date_time]
DATETIME_CONFIG = CURRENT
TRANSFORMS-get-date = construct_compound_date
SHOULD_LINEMERGE=false
LINE_BREAKER=([\n\r]+)

# This configuration is applied to all sourcetypes and it adds an indexed field with len of the event
# This is very useful for using with tstats to sum up all ingested data from any source very quickly
[default]
TRANSFORM-all-data= add_raw_length_to_meta_field

[reduced_columns]
DATETIME_CONFIG = CURRENT
INDEXED_EXTRACTIONS = CSV
TRANSFORMS-drop_fields = drop_useless_fields
EXTRACT-removed-columns= [^,]+,[^,]+,[^,]+,(?<random_nonsense>[^,]+),(?<long_payload>[^,]+)

# this is an example for importing data from an external splunk instance
[import_data]
DATETIME_CONFIG = CURRENT
TRANSFORMS-extract-metadata = drop_header, extract_metadata_copy_to_meta, reassign_meta_to_metadata, remove_metadata_from_raw
SEDCMD-strip_double_quotes= s/""/"/g

[split_output]
TIME_PREFIX = ^
TIME_FORMAT = %Y-%m-%d %H:%M:%S
SHOULD_LINEMERGE=false
LINE_BREAKER=([\n\r]+)

# This sourcetype is an example for how we can use REPEAT_MATCH and regex to automatically extract fields from log files
[indexed_log]
TIME_PREFIX = ^
TIME_FORMAT = %Y-%m-%d %H:%M:%S
SHOULD_LINEMERGE=false
LINE_BREAKER=([\n\r]+)
TRANSFORMS-extract_indexed_fields=regex_extract_doubled_quoted_av_pairs, regex_extract_single_quoted_av_pairs, regex_extract_unquoted_av_pairs
