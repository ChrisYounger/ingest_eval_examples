# This sourcetype is for the conflicting timestamps usecase, it calls a transform to extract the 
# datetime format via INGEST_EVAL and the strptime function
[demutliplexed_datetime_formats]
DATETIME_CONFIG = CURRENT
TRANSFORMS-extract_date = demultiplex_datetime

# This sourcetype is for the compound datetimes examples where the file name encodes the date stamp
# but the timestamp is per log line
[compound_date_time]
DATETIME_CONFIG = CURRENT
TRANSFORMS-get-date = construct_compound_date
SHOULD_LINEMERGE=false
LINE_BREAKER=([\n\r]+)

# This configuration is applied to all sourcetypes and it adds an indexed field with len of the event
# This is very useful for using with tstats to sum up all ingested data from any source very quickly
[default]
TRANSFORM-all-data= add_raw_length_to_meta_field

# this is an example for removing unwanted indexed fields from a CSV file
[reduce_columns]
# The timestamp is found in the time column, we need to remove this column
TIMESTAMP_FIELDS=time
INDEXED_EXTRACTIONS = CSV
# These transforms remove the useless columns, and also the useless time fields
TRANSFORMS-drop_fields = drop_useless_columns, drop_useless_time_fields
# Lift the removed columns via search time exraction (only works in the app)
EXTRACT-removed-columns= [^,]+,[^,]+,[^,]+,(?<random_nonsense>[^,]+),(?<long_payload>[^,]+)

# this is an example for importing data from an external splunk instance
[import_data]
# time is stored in epoch at the start of each line
TIME_FORMAT = %s.%3Q
TIME_PREFIX = ^
# the transform required to drop the header extract the metafields and copy to the correct fields
TRANSFORMS-extract-metadata = drop_header, extract_metadata_copy_to_meta, reassign_meta_to_metadata, remove_metadata_from_raw
# Splunk uses double quotes to escape quotes, we want to remove this before we start extracting the fields
SEDCMD-strip_double_quotes= s/""/"/g
# The solution supports multiline events
LINE_BREAKER=(\^\^\^END\^\^\^"\n)
SHOULD_LINEMERGE=false

[split_output]
TIME_PREFIX = ^
TIME_FORMAT = %Y-%m-%d %H:%M:%S
SHOULD_LINEMERGE=false
LINE_BREAKER=([\n\r]+)

# This sourcetype is an example for how we can use REPEAT_MATCH and regex to automatically extract fields from log files
[indexed_log]
TIME_PREFIX = ^
TIME_FORMAT = %Y-%m-%d %H:%M:%S
SHOULD_LINEMERGE=false
LINE_BREAKER=([\n\r]+)
# because we are creating indexed fields we can disable the major breakers
SEGMENTATION = search
TRANSFORMS-extract_indexed_fields=regex_extract_doubled_quoted_av_pairs, regex_extract_single_quoted_av_pairs, regex_extract_unquoted_av_pairs

[advanced_masking]
TIME_PREFIX = ^
TIME_FORMAT = %Y-%m-%d %H:%M:%S
SHOULD_LINEMERGE=false
LINE_BREAKER=([\n\r]+)
TRANSFORMS-apply-masking=extract_email