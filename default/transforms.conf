# conflicting_datetime_formats

#  This transform tests three different date time formats and selects the first match
[conflicting_datetime_formats-test_try_formats]
INGEST_EVAL= _time=case(isnotnull(strptime(_raw, "%c")), strptime(_raw, "%c"), isnotnull(strptime(_raw, "%H:%M:%S %y-%m-%d")),strptime(_raw, "%H:%M:%S %y-%m-%d"), isnotnull(strptime(_raw, "%Y-%m-%d %H:%M:%S")), strptime(_raw, "%Y-%m-%d %H:%M:%S"))

# use regex replace to pop out the date form the source, append on the first 10 chars from _raw and then run through strftime.
# if the eval fails to execute, CURRENT time will be kept
[compound_datetimes-join_and_parse]
INGEST_EVAL= _time=strptime(replace(source,".*/(20\d\d\-\d\d\-\d\d)\.log","\1").substr(_raw,0,10),"%Y-%m-%d%H:%M:%S"), my_date:=null() 

# add the length of the _raw string to the event as a hidden field, this needs to be the last transform so we don't change the
# length of _raw again once the value has been computed
[add_event_length-get_raw_length]
INGEST_EVAL= _event_length=len(_raw)

# To drop a field from _meta we need to overwrite any previous value using the := assignment option
[drop_indexed_fields-drop_useless_columns]
INGEST_EVAL= time:=null(), repeated_field:=null(), random_nonsense:=null(), long_payload:=null()

# To drop a field from _meta we need to overwrite any previous value using the := assignment option
[shared-drop_useless_time_fields]
INGEST_EVAL= timestartpos:=null(), timeendpos:=null(), date_second:=null(), date_hour:=null(), date_minute:=null(), date_year:=null(), date_month:=null(), date_mday:=null(),  date_wday:=null(), date_zone:=null()


# the header field form a Splunk CSV export starts with the first row being named after the header _raw. We want to drop these
[load_into_indexes-drop_header]
INGEST_EVAL = queue=if(_raw="\"_raw\"","nullQueue", queue)

# We use REGEX to pop out the values for index, host, sourcetype & source, we then write them to tempory variables in _meta.
# We assume that % is not found in the primary keys to optimize the REGEX
[load_into_indexes-extract_metadata_copy_to_meta]
SOURCE_KEY=_raw
WRITE_META = true
REGEX = ^"\d+(?:\.\d+)?%%%([^%]+)%%%([^%]+)%%%([^%]+)%%%([^%]+)%%%
FORMAT = my_index::"$1" my_host::"$2" my_source::"$3" my_sourcetype::"$4"

# copy the temporary user defined fields into the primary metadata locations and then delete the temporary fields
[load_into_indexes-reassign_meta_to_metadata]
INGEST_EVAL = host:=my_host, source:=my_source, index:=my_index, sourcetype:=my_sourcetype, my_host:=null(), my_source=null(), my_index:=null(), my_sourcetype:=null()

# extract the _raw field from the protocol and write back to _raw
[load_into_indexes-remove_metadata_from_raw]
INGEST_EVAL = _raw=replace(_raw, "^[^%]+%%%(?:[^%]+)%%%(?:[^%]+)%%%(?:[^%]+)%%%(?:[^%]+)%%%(.*)","\1")

# debug function that copies the contents of the _meta field into the _raw field so we can see what is being routed to indexing
[debug-copy_meta_to_raw]
SOURCE_KEY = _meta
DEST_KEY = _raw
REGEX = (.*)
FORMAT = $1


# this regex finds unquote quoted attribute value pairs, ie the form a=b, and appends them to _meta
[auto_extract_indexed_fields-univeral]
SOURCE_KEY = _raw
REGEX = \s([a-zA-Z][a-zA-Z0-9_-]+)=(?:"([^"]+)"|'([^']+)'|([^\s"',]+))
REPEAT_MATCH=true
FORMAT = $1::"$2$3$4"
WRITE_META = true

# this transform randomly assigns each event to one of the two output groups by appending a 0 or 1 to the named output group
[split_forwarding-randomize_output]
INGEST_EVAL = _TCP_ROUTING="split_forwarding_".random()%2

# create a copy of the license log files, we leave the orginal event to be written into the _internal index as normal
[metricify_license-clone]
REGEX = .
CLONE_SOURCETYPE = metricify_license
FORMAT = $0
DEST_KEY = _raw

# We use a REGEX transformation to lift the fields and then write them to indexed fields, the value for b becomes _value which is the 
# metric value, the remaining fields will become dimensions, we hard code the metric name to become license_usage
# we create two mutally exclusive capture groups for each field that may or may not be quoted with strings, and assign both to the indexed field 
[metricify_license-extract_fields]
SOURCE_KEY = _raw
REGEX = type=(\S+)\ss=(?:"([^"]*)"|(\S*))\s+st=(?:"([^"]+)"|(\S+))\s+h=(?:"([^"]+)"|(\S+))\so="[^"]*"\sidx=(?:"([^"]+)"|(\S+))\si="([^"]+)"\spool="([^"]+)"\sb=(\d+)\spoolsz=(\d+)
FORMAT = metric_name::"license_usage" type::"$1" from_source::"$2$3" from_sourcetype::"$4$5" from_host::"$6$7" into_index::"$8$9" on_indexer::"$10" allocated_to_pool::"$11" _value::"$12" pool_size::"$13"
WRITE_META = true

# We keep data when type=usage, copy the metadata into the proper fields, drop the immediate indexed fields, and then route the metrics data into the _metrics index
[metricify_license-reassign_meta_fields_and_route_to_index]
INGEST_EVAL = queue=if(type="Usage", queue, "nullQueue"), host=from_host, sourcetype=from_sourcetype, source=from_source,  type:=null(), from_host:=null(), from_sourcetype:=null(), from_source:=null(), index:="_metrics"

[mask_and_clone-extract_email_password]
SOURCE_KEY = _raw
WRITE_META = true
REGEX = email_address=(\S+@\S+) password="([^"]+)"
FORMAT = email_address::"\1" password="\2"

[mask_and_clone-encode_fields]
INGEST_EVAL = email_encoded=sha1(email_address), password=sha1(password)
