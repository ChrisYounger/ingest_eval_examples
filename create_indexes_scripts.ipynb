{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas\n",
    "import math\n",
    "import random\n",
    "import datetime\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_lines=[\"splunk> Finding your faults, just like mom.\", \n",
    "    \"splunk> because ninjas are too busy\", \n",
    "    \"splunk> All batbelt. No tights.\", \n",
    "    \"splunk> Digs deeper than a jealous spouse.\", \n",
    "    \"splunk> More flexible than an Olympic gymnast.\", \n",
    "    \"splunk> The mars rover of the IT landfill.\", \n",
    "    \"Splunk> The IT Search Engine.\", \n",
    "    \"Splunk> Be an IT superhero. Go home early.\", \n",
    "    \"Splunk> CSI: Logfiles.\", \n",
    "    \"Splunk> Needle. Haystack. Found.\", \n",
    "    \"Splunk> All batbelt. No tights.\", \n",
    "    \"Splunk> Finding your faults, just like mom.\", \n",
    "    \"Splunk> Australian for grep.\", \n",
    "    \"Splunk> 4TW\", \n",
    "    \"Splunk> See your world. Maybe wish you hadnâ€™t.\", \n",
    "    \"Splunk> Like an F-18, bro.\", \n",
    "    \"Splunk> Now with more code!\", \n",
    "    \"Splunk> Winning the War on Error\", \n",
    "    \"Splunk> The Notorious B.I.G. D.A.T.A.\", \n",
    "    \"Splunk> Map. Reduce. Recycle.\", \n",
    "    \"Splunk> Take the sh out of IT.\", \n",
    "    \"Splunk> I like big data and I cannot lie.\", \n",
    "    \"splunk> I gotta fever, and the only cure is MOAR LICENSE!\", \n",
    "    \"splunk> The corkscrew for your vintage data.\", \n",
    "    \"splunk> Caught me on the server - Wasn't me.\", \n",
    "    \"splunk> \\\"\\\"\\. nuff said.\", \n",
    "    \"splunk> These are the droids you are looking for\", \n",
    "    \"splunk> Finding disturbances in the Force before the Jedi Masters\", \n",
    "    \"splunk> don't get caught up in the game of pwns\", \n",
    "    \"splunk> We enjoy breaks more than Unions\", \n",
    "    \"splunk> We line break for regular expressions\", \n",
    "    \"splunk> The bran for your system\", \n",
    "    \"splunk> Open a can of whooparse\", \n",
    "    \"splunk> Show me your logs\", \n",
    "    \"splunk> Rhymes with drunk\", \n",
    "    \"splunk> Chasing tail since 2003\", \n",
    "    \"splunk> this way: Run-D.M.C.\", \n",
    "    \"splunk> Walking War Room!!\", \n",
    "    \"splunk> IT like you mean it\", \n",
    "    \"splunk ML> Solve problems you didn't know you were about to have\", \n",
    "    \"Splunk> see the forest, and the trees\", \n",
    "    \"Splunk> data with destiny\", \n",
    "    \"Splunk> see the light before you tunnel\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_range_days=5\n",
    "sample_readings=100\n",
    "seconds_in_day=24*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes =[]\n",
    "for i in range(1,sample_readings) :\n",
    "    random_seconds = random.randrange(1, date_range_days*seconds_in_day)\n",
    "    datetimes.append(datetime.timedelta(seconds=-random_seconds))\n",
    "\n",
    "datetimes.sort(reverse=True)\n",
    "\n",
    "datetime_format = [\"%Y-%m-%d %H:%M:%S\", \"%H:%M:%S %y-%m-%d\", \"%c\"]\n",
    "\n",
    "mutliplexed_datetime_formats = open(\"sample/conflicting_dates/mutliplexed_datetime_formats.log\",\"w\")\n",
    "\n",
    "for i in datetimes :\n",
    "    mutliplexed_datetime_formats.write((datetime.datetime.now()-i).strftime(random.choice(datetime_format))+\" \"+random.choice(log_lines)+\"\\n\")\n",
    "\n",
    "mutliplexed_datetime_formats.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_map = {}\n",
    "\n",
    "for i in range(1,sample_readings) :\n",
    "    random_seconds = random.randrange(1, 24*60*60)\n",
    "    random_day = random.randrange(0,date_range_days)\n",
    "    if random_day not in date_map :\n",
    "        date_map[random_day] = [datetime.timedelta(days=-random_day, seconds=-random_seconds)]\n",
    "    else:\n",
    "        date_map[random_day].append(datetime.timedelta(days=-random_day, seconds=-random_seconds))\n",
    "    \n",
    "for i in date_map.keys() :\n",
    "    filename=\"sample/compound_date_time/\"+(datetime.datetime.now()-datetime.timedelta(days=-i)).strftime(\"%Y-%m-%d\")+\".log\"\n",
    "    file_for_day = open(filename,\"w\")\n",
    "    date_map[i].sort(reverse=True)\n",
    "    for t in date_map[i] :\n",
    "        timestamp = (datetime.datetime.now()-t).strftime(\"%H:%M:%S\")\n",
    "        file_for_day.write(timestamp+\" \"+random.choice(log_lines)+\"\\n\")\n",
    "    file_for_day.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_columns=pandas.DataFrame(columns=['primary_key', 'primary_value', 'repeated_field', 'random_nonsense', 'long_payload'])\n",
    "\n",
    "for i in range(0,sample_readings) :\n",
    "    useless_columns=useless_columns.append({'primary_key': i, 'primary_value': random.randint(0,999999), 'repeated_field': \"same silly value\", 'random_nonsense' : uuid.uuid4(), 'long_payload' : random.choice(log_lines)}, ignore_index=True)\n",
    "\n",
    "useless_columns.to_csv('sample/drop_useless_columns/useless_columns.csv', sep=',', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes=['ingest_bob', 'ingest_tom', 'ingest_buttercup']\n",
    "sourcetypes=[('ingest_bananas', \"%c\"), ('ingest_meat', \"%Y-%m-%d %H:%M:%S\"), ('ingest_pairs', \"%H:%M:%S %y-%m-%d\"), ('ingest_apples', \"%d %a %Y %H:%M:%S\")]\n",
    "sources=['sea', 'ground', 'sky', 'tree']\n",
    "hosts=['server', 'laptop', 'phone']\n",
    "\n",
    "import_events = open('sample/import_data/encoded_splunk_events.txt',\"w\")\n",
    "\n",
    "mutliplexed_datetime_formats = open(\"sample/conflicting_dates/mutliplexed_datetime_formats.log\",\"w\")\n",
    "sep=\"%%%\"\n",
    "\n",
    "for i in datetimes :\n",
    "    (sourcetype, datetime_format) = random.choice(sourcetypes)\n",
    "    time=str((datetime.datetime.now()-i).timestamp())\n",
    "    host=random.choice(hosts)\n",
    "    source=random.choice(sources)\n",
    "    index=random.choice(indexes)\n",
    "    raw=(datetime.datetime.now()-i).strftime(datetime_format)+\" \"+random.choice(log_lines)\n",
    "    row=time+sep+index+sep+host+sep+source+sep+sourcetype+sep+raw\n",
    "    import_events.write(row+\"\\n\")\n",
    "\n",
    "\n",
    "import_events.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}